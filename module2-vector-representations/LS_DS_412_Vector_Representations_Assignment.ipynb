{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "    import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Clean:* Job Listings from indeed.com that contain the title \"Data Scientist\" \n",
    "\n",
    "You have `job_listings.csv` in the data folder for this module. The text data in the description column is still messy - full of html tags. Use the [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library to clean up this column. You will need to read thru the documentation to accomplish this task. \n",
    "\n",
    "`Tip:` You will need to install the `bs4` library inside your conda environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "jobs = pd.read_csv(r'C:\\Users\\Emma\\Desktop\\DS-Unit-4-Sprint-1-NLP-master\\DS-Unit-4-Sprint-1-NLP-master\\module2-vector-representations\\data\\job_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"&lt;div&gt;&lt;div&gt;Job Requirements:&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'&lt;div&gt;Job Description&lt;br/&gt;\\n&lt;br/&gt;\\n&lt;p&gt;As a Da...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'&lt;div&gt;&lt;p&gt;As a Data Scientist you will be work...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'&lt;div class=\"jobsearch-JobMetadataHeader icl-...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'&lt;ul&gt;&lt;li&gt;Location: USA \\xe2\\x80\\x93 multiple ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"<div><div>Job Requirements:</div><ul><li><p>...   \n",
       "1           1  b'<div>Job Description<br/>\\n<br/>\\n<p>As a Da...   \n",
       "2           2  b'<div><p>As a Data Scientist you will be work...   \n",
       "3           3  b'<div class=\"jobsearch-JobMetadataHeader icl-...   \n",
       "4           4  b'<ul><li>Location: USA \\xe2\\x80\\x93 multiple ...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"<div><div>Job Requirements:</div><ul><li><p>\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them</p>\\\\n</li><li><p>Intermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)</p>\\\\n</li><li><p>Exposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R</p>\\\\n</li><li><p>Ability to communicate Model findings to both Technical and Non-Technical stake holders</p>\\\\n</li><li><p>Hands on experience in SQL/Hive or similar programming language</p>\\\\n</li><li><p>Must show past work via GitHub, Kaggle or any other published article</p>\\\\n</li><li><p>Master\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.</p></li></ul><div><div><div><div><div><div>\\\\nApply Now</div></div></div></div></div></div></div><div></div>\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = BeautifulSoup(jobs['description'][0], 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning each row into the beautifulsoup object\n",
    "jobs['description'] = jobs['description'].apply(lambda x: BeautifulSoup(x, 'html.parser'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the beautifulsoup function on each object to extract the text from html\n",
    "jobs['description'] = jobs['description'].apply(lambda x: x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\\\nConceptual understanding in Machine Learning models like Nai\\\\xc2\\\\xa8ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\\\nHands on experience in SQL/Hive or similar programming language\\\\nMust show past work via GitHub, Kaggle or any other published article\\\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\\\nApply Now\"'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import codecs\n",
    "\n",
    "#codecs.encode(jobs['description'][0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\nConceptual understanding in Machine Learning models like NaiÂ¨ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\nIntermediate to expert level coding skills in Python/R. (Ability to write functions, clean and efficient data manipulation are mandatory for this role)\\nExposure to packages like NumPy, SciPy, Pandas, Matplotlib etc in Python or GGPlot2, dplyr, tidyR in R\\nAbility to communicate Model findings to both Technical and Non-Technical stake holders\\nHands on experience in SQL/Hive or similar programming language\\nMust show past work via GitHub, Kaggle or any other published article\\nMaster\\'s degree in Statistics/Mathematics/Computer Science or any other quant specific field.\\nApply Now\"'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codecs.decode(jobs['description'][0], 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['description'] = jobs['description'].apply(lambda x: codecs.decode(x, 'unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Location: USA â multiple locations\\n2+ yea...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1           1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2           2  b'As a Data Scientist you will be working on c...   \n",
       "3           3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4           4  b'Location: USA â multiple locations\\n2+ yea...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample = jobs['description'][0].encode(encoding='UTF-8',errors='strict')\n",
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aample2 = sample.decode(encoding='UTF-8',errors='strict')\n",
    "#aample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codecs.decode(aample2, 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aample2.decode(encoding='UTF-8',errors='strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ftfy \n",
    "\n",
    "#ftfy.fix_text(jobs['description'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"Job Requirements:\\nConceptual understanding ...</td>\n",
       "      <td>Data scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'Job Description\\n\\nAs a Data Scientist 1, yo...</td>\n",
       "      <td>Data Scientist I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'As a Data Scientist you will be working on c...</td>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'$4,969 - $6,756 a monthContractUnder the gen...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>b'Location: USA \\xe2\\x80\\x93 multiple location...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  b\"Job Requirements:\\nConceptual understanding ...   \n",
       "1           1  b'Job Description\\n\\nAs a Data Scientist 1, yo...   \n",
       "2           2  b'As a Data Scientist you will be working on c...   \n",
       "3           3  b'$4,969 - $6,756 a monthContractUnder the gen...   \n",
       "4           4  b'Location: USA \\xe2\\x80\\x93 multiple location...   \n",
       "\n",
       "                          title  \n",
       "0               Data scientist   \n",
       "1              Data Scientist I  \n",
       "2  Data Scientist - Entry Level  \n",
       "3                Data Scientist  \n",
       "4                Data Scientist  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#actual tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = nlp.Defaults.stop_words.union(['\\n', 'r', '\\n\\n', '1,', 'b\"job', 'data','work','business','learning','machine','science','analytics',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "\"\"\" Update those tokens w/o stopwords\"\"\"\n",
    "for doc in tokenizer.pipe(jobs['description'], batch_size=500):\n",
    "    \n",
    "    doc_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in STOP_WORDS)&(token.is_stop == False) & (token.is_punct == False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "jobs['des_tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-193-71cacc598028>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-193-71cacc598028>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    return column = tokens\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def tokenize(column):\n",
    "    for doc in tokenizer.pipe(column, batch_size=500):\n",
    "        doc_tokens = []\n",
    "        \n",
    "        for token in doc:\n",
    "            if (token.text.lower() not in STOP_WORDS)&(token.is_stop == False) & (token.is_punct == False):\n",
    "                doc_tokens.append(token.text.lower())\n",
    "            \n",
    "        tokens.append(doc_tokens)\n",
    "    \n",
    "return column = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['requirements:',\n",
       " 'conceptual',\n",
       " 'understanding',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'models',\n",
       " 'like',\n",
       " 'naiâ¨ve',\n",
       " 'bayes,',\n",
       " 'k-means,',\n",
       " 'svm,',\n",
       " 'apriori,',\n",
       " 'linear/',\n",
       " 'logistic',\n",
       " 'regression,',\n",
       " 'neural,',\n",
       " 'random',\n",
       " 'forests,',\n",
       " 'decision',\n",
       " 'trees,',\n",
       " 'k-nn',\n",
       " 'hands-on',\n",
       " 'experience',\n",
       " '2',\n",
       " 'intermediate',\n",
       " 'expert',\n",
       " 'level',\n",
       " 'coding',\n",
       " 'skills',\n",
       " 'python/r.',\n",
       " '(ability',\n",
       " 'write',\n",
       " 'functions,',\n",
       " 'clean',\n",
       " 'efficient',\n",
       " 'data',\n",
       " 'manipulation',\n",
       " 'mandatory',\n",
       " 'role)',\n",
       " 'exposure',\n",
       " 'packages',\n",
       " 'like',\n",
       " 'numpy,',\n",
       " 'scipy,',\n",
       " 'pandas,',\n",
       " 'matplotlib',\n",
       " 'etc',\n",
       " 'python',\n",
       " 'ggplot2,',\n",
       " 'dplyr,',\n",
       " 'tidyr',\n",
       " 'ability',\n",
       " 'communicate',\n",
       " 'model',\n",
       " 'findings',\n",
       " 'technical',\n",
       " 'non-technical',\n",
       " 'stake',\n",
       " 'holders',\n",
       " 'hands',\n",
       " 'experience',\n",
       " 'sql/hive',\n",
       " 'similar',\n",
       " 'programming',\n",
       " 'language',\n",
       " 'past',\n",
       " 'work',\n",
       " 'github,',\n",
       " 'kaggle',\n",
       " 'published',\n",
       " 'article',\n",
       " \"master's\",\n",
       " 'degree',\n",
       " 'statistics/mathematics/computer',\n",
       " 'science',\n",
       " 'quant',\n",
       " 'specific',\n",
       " 'field.',\n",
       " 'apply',\n",
       " 'now\"']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['des_tokens'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vectorizer(column):\n",
    "    for x in column:\n",
    "        vect= CountVectorizer(stop_words='english', max_df=.05)\n",
    "        vect.fit(x)\n",
    "    dtm = vect.transform(jobs['des_tokens'])\n",
    "    dtm = pd.DataFrame(dtm.todense(), columns= vect.get_feature_names)\n",
    "    return dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer(jobs['des_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', max_df=.95)\n",
    "\n",
    "vect.fit(jobs['description'])\n",
    "\n",
    "dtm = vect.transform(jobs['description'])\n",
    "\n",
    "dtm = pd.DataFrame(dtm.todense(), columns= vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02115</th>\n",
       "      <th>03</th>\n",
       "      <th>0305</th>\n",
       "      <th>0356</th>\n",
       "      <th>04</th>\n",
       "      <th>062</th>\n",
       "      <th>06366</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>zf</th>\n",
       "      <th>zfâ</th>\n",
       "      <th>zheng</th>\n",
       "      <th>zillow</th>\n",
       "      <th>zogsports</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurichâ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8652 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02115  03  0305  0356  04  062  06366  08  ...  zf  zfâ  zheng  \\\n",
       "0   0    0      0   0     0     0   0    0      0   0  ...   0    0      0   \n",
       "1   0    0      0   0     0     0   0    0      0   0  ...   0    0      0   \n",
       "2   0    0      0   0     0     0   0    0      0   0  ...   0    0      0   \n",
       "3   0    0      0   0     0     0   0    0      0   0  ...   0    0      1   \n",
       "4   0    0      0   0     0     0   0    0      0   0  ...   0    0      0   \n",
       "\n",
       "   zillow  zogsports  zones  zoom  zuckerberg  zurich  zurichâ  \n",
       "0       0          0      0     0           0       0        0  \n",
       "1       0          0      0     0           0       0        0  \n",
       "2       0          0      0     0           0       0        0  \n",
       "3       0          0      0     0           0       0        0  \n",
       "4       0          0      0     0           0       0        0  \n",
       "\n",
       "[5 rows x 8652 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5LB00uyZKV5"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "\n",
    "jobs['des_tokens'].apply(lambda x: word_counts.update(x))\n",
    "\n",
    "top_ten = word_counts.most_common(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 1667),\n",
       " ('team', 786),\n",
       " ('statistical', 542),\n",
       " ('new', 519),\n",
       " ('ability', 502),\n",
       " ('product', 479),\n",
       " ('skills', 453),\n",
       " ('help', 448),\n",
       " ('working', 441),\n",
       " ('models', 437)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have to seperate the tuples into x and y to plot\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for z in top_ten:\n",
    "    x.append(z[0])\n",
    "    y.append(z[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I decided to add some of these words to the stop list cause they seemed kind of basic\n",
    "#but the new top words are as well, so maybe I will come back to this and be more selective\n",
    "\n",
    "['data',\n",
    " 'experience',\n",
    " 'work',\n",
    " 'business',\n",
    " 'team',\n",
    " 'learning',\n",
    " 'machine',\n",
    " 'science',\n",
    " 'analytics',\n",
    " 'statistical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    \n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>401(k</th>\n",
       "      <th>...</th>\n",
       "      <th>ï deliver</th>\n",
       "      <th>ï delivery</th>\n",
       "      <th>ï end</th>\n",
       "      <th>ï expertise</th>\n",
       "      <th>ï great</th>\n",
       "      <th>ï lead</th>\n",
       "      <th>ï phd</th>\n",
       "      <th>ï prove</th>\n",
       "      <th>ï run</th>\n",
       "      <th>ï vudu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1   10   100   11         2    3    4   401(k  ...  \\\n",
       "0  0.0  0.0  0.00000  0.0   0.0  0.0  0.000000  0.0  0.0     0.0  ...   \n",
       "1  0.0  0.0  0.04218  0.0   0.0  0.0  0.000000  0.0  0.0     0.0  ...   \n",
       "2  0.0  0.0  0.00000  0.0   0.0  0.0  0.000000  0.0  0.0     0.0  ...   \n",
       "3  0.0  0.0  0.00000  0.0   0.0  0.0  0.000000  0.0  0.0     0.0  ...   \n",
       "4  0.0  0.0  0.00000  0.0   0.0  0.0  0.144757  0.0  0.0     0.0  ...   \n",
       "\n",
       "   ï deliver  ï delivery  ï end  ï expertise  ï great  ï lead  \\\n",
       "0          0.0           0.0      0.0            0.0        0.0       0.0   \n",
       "1          0.0           0.0      0.0            0.0        0.0       0.0   \n",
       "2          0.0           0.0      0.0            0.0        0.0       0.0   \n",
       "3          0.0           0.0      0.0            0.0        0.0       0.0   \n",
       "4          0.0           0.0      0.0            0.0        0.0       0.0   \n",
       "\n",
       "   ï phd  ï prove  ï run  ï vudu  \n",
       "0      0.0        0.0      0.0       0.0  \n",
       "1      0.0        0.0      0.0       0.0  \n",
       "2      0.0        0.0      0.0       0.0  \n",
       "3      0.0        0.0      0.0       0.0  \n",
       "4      0.0        0.0      0.0       0.0  \n",
       "\n",
       "[5 rows x 12291 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english',\n",
    "                       ngram_range=(1,2),\n",
    "                       max_df=.5,\n",
    "                       min_df=3,\n",
    "                       tokenizer= tokenize)\n",
    "\n",
    "dtm = tfidf.fit_transform(jobs['description'])\n",
    "                       \n",
    "dtm = pd.DataFrame(dtm.todense(), columns = tfidf.get_feature_names())\n",
    "                       \n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 1.3252469 , 1.33270533, 1.34709867, 1.35092416]]),\n",
       " array([[  0, 115, 274, 338,   5]], dtype=int64))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"Job Requirements:\\nConceptual understanding in Machine Learning models like NaiÂ¨ve Bayes, K-Means, SVM, Apriori, Linear/ Logistic Regression, Neural, Random Forests, Decision Trees, K-NN along with hands-on experience in at least 2 of them\\nIntermediate to expert level coding skills in Python/R. (A'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][0][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"b'General Description:\\nAssist researchers and software developers on projects bridging the gap between research and analytics by providing data-driven solutions across several policy areas.\\nWork with research and analytics staff in development of streamlined protocols through gathering requirements.\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][274][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_listing = [''' Our company is seeking an experienced data scientist to work toward our goals\n",
    "of improving the environment and slowing climate change using neural networks to drive change. \n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x12291 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = tfidf.transform(sample_listing)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.33601569, 1.33894347, 1.34423741, 1.36197415, 1.36616478]]),\n",
       " array([[299, 295,  21, 346, 399]], dtype=int64))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\\'Company: AllazoHealth\\nLocation: New York City\\n\\nAllazoHealth, one of the fastest growing health-tech startups in NYC, combines\\nbehavioral science with data mining and machine learning to help stakeholders across\\nthe healthcare spectrum influence patients to adopt healthier behaviors. Our propriety\\nAI platform, AllazoEngine TM provides individualized intervention targeting for medication\\nadherence, disease management, and wellness programs.\\n\\nPosition: Data Scientist\\n\\nWe are currently seeking an experienced data scientist with a background in machine\\nlearning and predictive analytics.\\n\\nRequirements:\\n\\nStrong background (minimum 4-6 years) in SQL\\nDemonstrated success in high growth and early-stage environment\\nDemonstrated GSD \"Get Stuff Done\" attitude and results\\nStrong influencer and communicator across all levels of the organization\\nDetail and metric-oriented\\nProficient in Microsoft Office and technology\\n\\nResponsibilities:\\n\\nHelp manage technical planning and activities for all client implementations\\nIdentifying areas of opportunities and providing machine learning solutions to\\n\\nenhance AllazoEngine\\n\\nBuild client reporting from performance monitoring to ad hoc requests\\nProvide planning and continuous development of the database architecture\\n\\nBenefits:\\n\\nVery competitive compensation package including cash and equity stock options\\nMedical/Dental/Vision Benefits\\nFlat organizational style which empowers everyone in the company to help achieve\\n\\nboth company and personal goals\\n\\nWeekly team outings and high focus on continuously building team rapport and\\n\\nculture as we continue on this incredible growth curve\\n\\nCompany description:\\nAllazo Health is a high-growth, profitable healthtech start-up founded in 2012 that is\\nleading the development and deployment of revolutionary analytical solutions which is\\nhelping patient outcomes and medical costs by influencing patients to adopt healthier\\nbehaviors.\\n\\nIf you are passionate about healthcare, are driven to save lives while delivering\\ntremendous value to Fortune 100 customers, and want to make a significant impact\\nwithin a tremendously fast-growing company, then this is the job for you.\\n\\nOur customers include some of the largest pharma companies, PBMs, payors, and\\nproviders. Backed by extremely sophisticated investors and a strong management\\''"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][299]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b\"What youâ\\x80\\x99ll be doing...\\nStrategic Modeling & Planning team is hiring a strategic thinker to join a high profile, high visibility team that powers Network analytics and strategic thinking for Verizon. You will be part of a team that drives business decisions and optimized capital investment for the Verizon Wireless and Wireline Networks. That includes building tools, creating analyses, and discovering insights into our Networks that can be used to optimize the capital plan.\\nThe team creates actionable operational and strategic insights as well as visualizations for senior leaders in the company across multiple organizations. You will be part of the team that shapes multi-billion dollar investments for the nationâ\\x80\\x99s largest and best networks and guiding Verizon into future network investments. This is a job for an intelligent, decisive, quick, forward-thinking, strategic, and tactical thought leader. This person should have exceptional influencing skills and preferred experience working across areas and levels of an organization. Specifically this person will be building capital models that optimize network spend and capacity deployment for various networks.\\nData Science:\\nArchitect and design solutions to complex predictive & prescriptive modeling challenges including capital optimization across Verizonâ\\x80\\x99s Networks.\\nResearch and develop analyses, forecasts, and optimization methods to improve the quality of Network quality of service; example application areas include throughput optimization & end-user behavioral modeling.\\nDevelop and implement machine learning and optimization algorithms across multiple platforms to create scalable solutions with actionable insights from complex data sets.\\nLead strategic efforts across the Network organization, leveraging advanced analytics to optimize processes and procedures that lead to improved Network KPIs, capital optimization and cost reduction.\\nUse statistical modeling and analysis to understand relationships between diverse forms of customer data, network data and business KPI\\'.\\nDesign and implement data architecture, analytics environments, and methodologies for analyzing and storing large sets of structured and unstructured data.\\nBusiness Intelligence:\\nMake business recommendations (e.g. cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.\\nDefine key success metrics and create dashboards / reports to communicate results and monitor KPIs.\\nLead the creation of new data processes as identified through industry benchmarking and collaboration with Verizon\\'s data scientist community.\\nCross Functional Collaboration:\\nManage multiple projects simultaneously, adapt to changing priorities and meet aggressive deadlines.\\nBeing the go-to-person for network & technical modeling questions, including familiarity with next-gen network architecture and applications.\\nCollaborate with IT and business stakeholders to ensure data governance audit standards.\\nParticipate in cross-functional project teams as predictive modeling subject matter expert.\\nExecutive Presentations:\\nAnalyze complex data sets, draw conclusions and relationships and develop actionable recommendations.\\nEffectively communicate actionable insights to category leads supporting their goals and objectives.\\nPrepare executive level presentations to clearly articulate results of complex mathematical analyses.\\nWhat weâ\\x80\\x99re looking for...\\nYouâ\\x80\\x99ll need to have:\\nBachelorâ\\x80\\x99s degree or four or more years of work experience.\\nSix or more years of relevant work experience.\\nExperience in the development of predictive models.\\nEven better if you have:\\nMasterâ\\x80\\x99s degree in Business Analytics or a quantitative discipline (e.g., computer science, computer engineering, statistics, operations research, industrial engineering, applied economics, mathematics, physics, electrical engineering, industrial engineering).\\nExperience programming/scripting/coding (SQL, Python, R, etcâ\\x80¦) and knowledge of relational databases.\\nExperience with business intelligence tools (Tableau, Alteryx, PowerPivot).\\nExperience in data modeling, programming, data mining, large scale data acquisition, transformation and cleaning of structured and unsecured data.\\nAbility to adapt to new challenges to overcome short-term hurdles by staying focused on the teamâ\\x80\\x99s deliverables.\\nHigh level of curiosity and investigative mind-set with an attention to detail.\\nWork experience in a Capital Modeling or Business Predictive Analytics role.\\nWhen you join Verizon...\\nYouâ\\x80\\x99ll be doing work that matters alongside other talented people, transforming the way people, businesses and things connect with each other. Beyond powering Americaâ\\x80\\x99s fastest and most reliable network, weâ\\x80\\x99re leading the way in broadband, cloud and security solutions, Internet of Things and innovating in areas such as, video entertainment. Of course, we will offer you great pay and benefits, but weâ\\x80\\x99re about more than that. Verizon is a place where you can craft your own path to greatness. Whether you think in code, words, pictures or numbers, find your future at Verizon.\\nEqual Employment Opportunity\\nWe\\'re proud to be an equal opportunity employer- and celebrate our employees\\' differences,including race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, and Veteran status. Different makes us better.\"'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['description'][346]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
